{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "import json\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://recruiting.ultipro.com/NAT1011NATPR/JobBoard/af823b19-a43b-4cda-b6c2-c06508d84cf6\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_requests(url):\n",
    "    page = requests.get(url)\n",
    "    if page.status_code == 200:\n",
    "        soup = BeautifulSoup(page.text, 'html.parser')\n",
    "        return (soup)\n",
    "    else:\n",
    "        return(f\"Error: {page.status_code}\")    \n",
    "\n",
    "def scrape_selenium(driver, url):\n",
    "    driver.get(url)\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    return(soup)\n",
    "\n",
    "def selenium_driver():\n",
    "    chrome_options = Options()\n",
    "    driver = webdriver.Chrome(\n",
    "            ChromeDriverManager().install(),\n",
    "            options=chrome_options\n",
    "            )\n",
    "   \n",
    "    return(driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 100.0.4896\n",
      "Get LATEST chromedriver version for 100.0.4896 google-chrome\n",
      "Driver [C:\\Users\\nicho\\.wdm\\drivers\\chromedriver\\win32\\100.0.4896.60\\chromedriver.exe] found in cache\n",
      "C:\\Users\\nicho\\AppData\\Local\\Temp\\ipykernel_30000\\2012268719.py:2: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(\n"
     ]
    }
   ],
   "source": [
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")\n",
    "driver = webdriver.Chrome(\n",
    "        ChromeDriverManager().install(),\n",
    "        options=chrome_options\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def click(driver, by_locator):\n",
    "        WebDriverWait(driver, 10).until(EC.visibility_of_element_located(by_locator)).click()\n",
    "\n",
    "def is_visible(driver,by_locator):\n",
    "        element=WebDriverWait(driver, 10).until(EC.visibility_of_element_located(by_locator))\n",
    "        return bool(element)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NPR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Locators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MORE_JOBS_BUTTON=(By.XPATH,\"//*[@id='LoadMoreJobs']\")\n",
    "OPPORTUNITY_SUMMARY = (By.XPATH, \"//*[@aria-live='polite']\" )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adfasdf\n"
     ]
    }
   ],
   "source": [
    "driver.get(url)\n",
    "is_visible(driver, OPPORTUNITY_SUMMARY)\n",
    "\n",
    "loop = \"y\"\n",
    "while loop == \"y\":\n",
    "    try:\n",
    "        click(driver, MORE_JOBS_BUTTON)\n",
    "    except:        \n",
    "        loop = \"n\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, 'html.parser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_list_chunk = soup.find(\"div\", {\"id\": \"Opportunities\"})\n",
    "ls_jobs = job_list_chunk.find_all(\"div\", {\"data-automation\":\"opportunity\"})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape Information on All Jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "npr_jobs = []\n",
    "for job in ls_jobs:\n",
    "    title_chunk = job.find(\"a\", {\"data-automation\":\"job-title\"})\n",
    "    \n",
    "    try:\n",
    "        job_category = job.find(\"span\", {\"data-bind\":\"text: JobCategoryName()\"}).text\n",
    "    except:\n",
    "        job_category = \"NA\" \n",
    "    \n",
    "\n",
    "    try:\n",
    "        url = title_chunk[\"href\"]\n",
    "    except:\n",
    "        url = \"NA\"\n",
    "        \n",
    "    try:\n",
    "        job_category = job.find(\"span\", {\"data-bind\":\"text: JobCategoryName()\"}).text\n",
    "    except:\n",
    "        job_category = \"NA\"\n",
    "    try:\n",
    "        job_location = job.find(\"span\", {\"data-automation\":\"location-description\"}).text\n",
    "    except: \n",
    "        job_location = \"NA\"\n",
    "    try:\n",
    "        job_duration = job.find(\"span\", {\"data-automation\":\"job-hours\"}).text\n",
    "    except: \n",
    "        job_duration = \"NA\"\n",
    "    try:\n",
    "        job_title = title_chunk.text\n",
    "    except: \n",
    "        job_title = \"NA\"\n",
    "    try:\n",
    "        date_posted = job.find(\"small\", {\"data-automation\":\"opportunity-posted-date\"}).text\n",
    "        \n",
    "    except: \n",
    "        date_posted = \"NA\"\n",
    "\n",
    "    job = {\"company\": \"NPR\", \"job_title\": job_title,\"job_location\":job_location, \"job_duration\": job_duration,\"job_category\": job_category ,\"date_posted\": date_posted, \"url\":url, }\n",
    "    npr_jobs.append(job)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save and Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_npr_jobs = pd.DataFrame(npr_jobs)\n",
    "df_npr_jobs.to_csv(\"data/npr-jobs.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
